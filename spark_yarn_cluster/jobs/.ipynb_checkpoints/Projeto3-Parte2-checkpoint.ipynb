{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63182591",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "# <font color='blue'>Data Science Academy</font>\n",
    "## <font color='blue'>PySpark e Apache Kafka Para Processamento de Dados em Batch e Streaming</font>\n",
    "## <font color='blue'>Projeto 3</font>\n",
    "### <font color='blue'>Pipeline de Limpeza e Transformação Para Aplicações de IA com PySpark SQL</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c6d0b",
   "metadata": {},
   "source": [
    "## Pacotes Python Usados no Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181cb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.ml.evaluation as evals\n",
    "import pyspark.ml.tuning as tune\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import  VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import round, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e159cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633afd61",
   "metadata": {},
   "source": [
    "## Criando a Sessão Spark e Definindo o Nível de Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d44a0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/21 21:31:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/21 21:31:07 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# Cria a sessão Spark com YARN como gerenciador de recursos e especifica parâmetros do cluster\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Projeto3-Exp') \\\n",
    "    .master('yarn') \\\n",
    "    .config('spark.submit.deployMode', 'client') \\\n",
    "    .config('spark.driver.memory', '4g') \\\n",
    "    .config('spark.executor.memory', '1g') \\\n",
    "    .config('spark.executor.cores', '2') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9055d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nível de log\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665da3f6",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "## Carregando os Datasets a Partir do HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb722bd-73a0-46d8-9f48-5a1ea7c64d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Carrega o arquivo 1\n",
    "df_dsa_aeroportos = spark.read.csv(\"/opt/spark/data/dataset1.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07ddd4-7de6-4891-a9f8-916e62262b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_dsa_aeroportos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe512742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_aeroportos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a99882-5588-4e10-9af4-68a74b29466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo 2\n",
    "df_dsa_voos = spark.read.csv(\"/opt/spark/data/dataset2.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_voos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64508433-ef3f-45a0-9395-bdac80c39a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o arquivo 3\n",
    "df_dsa_aeronaves = spark.read.csv(\"/opt/spark/data/dataset3.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbb57d-335c-472d-97b7-b9886e8e8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_aeronaves.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0e416-d75e-4798-a44a-0e967227c3a2",
   "metadata": {},
   "source": [
    "Vamos converter esses dados para o formato:\n",
    "\n",
    "- Dados de entrada --> ['month', 'air_time', 'carr_fact', 'dest_fact', 'plane_age'] como o vetor features.\n",
    "- Dados de saída --> ['is_late'] com o nome label.\n",
    "\n",
    "E então usaremos os dados nesse formato para treinar e avaliar dois modelos de Machine Learning. Escolheremos o melhor modelo e então criaremos o job de automação do processo de treinamento no cluster Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8953f8",
   "metadata": {},
   "source": [
    "## Exploração e Limpeza dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc7e05-a1a6-47c6-8b54-4d3cc84d7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria tabela temporária\n",
    "df_dsa_voos.createOrReplaceTempView('voos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b918cf-c912-47fe-a036-7c9dd132a36c",
   "metadata": {},
   "source": [
    "Se você deseja executar consultas SQL diretamente sobre os dados, criar uma tabela temporária permite usar a sintaxe SQL para filtrar, agrupar e manipular os dados de forma que pode ser mais intuitiva ou mais fácil de expressar do que utilizando as APIs do DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista as tabelas\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31f5cc-c817-402b-976f-278e7fcf52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta SQL\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    carrier AS companhia_aerea,\n",
    "    COUNT(*) AS total_voos,\n",
    "    ROUND(AVG(dep_delay), 2) AS media_atraso_partida,\n",
    "    ROUND(AVG(arr_delay), 2) AS media_atraso_chegada,\n",
    "    MAX(dep_delay) AS maior_atraso_partida,\n",
    "    MAX(arr_delay) AS maior_atraso_chegada\n",
    "FROM \n",
    "    voos\n",
    "WHERE \n",
    "    dep_delay > 0 OR arr_delay > 0\n",
    "GROUP BY \n",
    "    carrier\n",
    "ORDER BY \n",
    "    media_atraso_chegada DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f4eb7-c4d9-4670-9411-6d5250d63cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa a consulta SQL e armazena o resultado em um DataFrame\n",
    "df_result = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556baa98-c20e-4858-8f3b-d129a9a69857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra o resultado\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ca0a3-4eb4-47c8-a52b-98b7f191eba7",
   "metadata": {},
   "source": [
    "Criar um DataFrame diretamente a partir de outro DataFrame é mais direto e consome menos recursos do que criar uma tabela temporária intermediária. Se seu uso é apenas para operações simples ou manipulações diretas, é mais eficiente trabalhar com o DataFrame diretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff6db2-58f5-4206-9523-b2f94028dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dataframe a partir da tabela temporária\n",
    "df_voos = spark.table('voos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f04972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c16545-6766-4e47-85e7-c806c80e426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a coluna de duração dos voos em horas (tarefa de engenharia de atributos)\n",
    "df_dsa_voos = df_dsa_voos.withColumn('duration_hrs', round(df_dsa_voos.air_time / 60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134518f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_voos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728f8b7-6e00-4962-a8f5-c5d4a9402662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro para visualizar os voos mais longos\n",
    "df_voos_longos_1 = df_dsa_voos.filter('distance > 1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda94395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voos_longos_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7655561-71f2-4f2d-b1bd-e6a25517f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena o DataFrame pela coluna 'duration_hrs' em ordem decrescente\n",
    "df_voos_longos_1_sorted = df_voos_longos_1.orderBy(desc('duration_hrs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2b50c-4062-4718-8552-da22801446cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe o resultado ordenado\n",
    "df_voos_longos_1_sorted.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f387849-8cce-46ff-87eb-2579450c0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesma regra anterior, com sintaxe diferente\n",
    "# Filtra os voos com distância maior que 1000 e ordena pela coluna 'distance' em ordem descendente\n",
    "df_voos_longos_2 = df_dsa_voos.filter(df_dsa_voos.distance > 1000).orderBy(desc('duration_hrs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33500703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voos_longos_2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ec40f-ef4c-4ccc-bf58-9bb75ae9d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando 3 colunas\n",
    "selected_1 = df_dsa_voos.select('tailnum', 'origin', 'dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f7792-1581-4e4c-ba2b-0650a50f095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select de 3 colunas com outra sintaxe\n",
    "temp = df_dsa_voos.select(df_dsa_voos.origin, df_dsa_voos.dest, df_dsa_voos.carrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e47d98a-4fb5-4065-8231-627789183def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando 2 filtros\n",
    "FilterA = df_dsa_voos.origin == 'SEA'\n",
    "FilterB = df_dsa_voos.dest == 'PDX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aa8e4-f757-4e51-b26c-fe9554ecf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função Filter com os filtros criados\n",
    "selected_2 = temp.filter(FilterA).filter(FilterB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1fc22-d595-4752-8aff-81f09c9adefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a velocidade média dos voos\n",
    "avg_speed = (round(df_dsa_voos.distance / (df_dsa_voos.air_time / 60), 2)).alias(\"avg_speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859bd5f-09ec-4284-9402-df49140fcc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_voos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a nova variável ao select\n",
    "speed_1 = df_dsa_voos.select('origin', 'dest', 'tailnum', avg_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6b7ea-9c41-47f1-b45b-b98982aa42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f863e0-21d8-4953-a7ca-dccd9a58c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo o cálculo direto no select\n",
    "speed_2 = df_dsa_voos.selectExpr('origin', 'dest', 'tailnum', 'round(distance/(air_time/60), 2) as avg_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ceafbc-07da-46db-93af-11009515f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo de 2 variáveis\n",
    "df_dsa_voos.describe('air_time', 'distance').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031fa23-f472-48e2-8703-296a47126e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra o tipo de dados de cada coluna\n",
    "df_dsa_voos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad8296-c6a4-475b-a9ff-40b13c6b43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando o tipo de dado de duas colunas\n",
    "df_dsa_voos = df_dsa_voos.withColumn('distance', df_dsa_voos.distance.cast('float'))\n",
    "df_dsa_voos = df_dsa_voos.withColumn('air_time', df_dsa_voos.air_time.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46790a-4c94-479c-bbe6-5955b3ecb576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra o tipo de dados de cada coluna\n",
    "df_dsa_voos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo de 2 variáveis\n",
    "df_dsa_voos.describe('air_time', 'distance').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27e8a4-deb8-457b-82b1-c9c6834680e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamento por aeronave\n",
    "by_plane = df_dsa_voos.groupBy('tailnum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33573c49-2bd1-4832-a096-a0327eaedb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem\n",
    "by_plane.count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee70d2a-0fe2-4b51-973b-74d9d54d6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamento por origem do voo\n",
    "by_origin = df_dsa_voos.groupBy('origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4061f8-4cf3-48cd-a8f9-1ae838f73684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média de tempo no ar por origem do voo\n",
    "by_origin.avg('air_time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a46588-dfdc-4ccc-b1cc-03b17c5d12fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo \n",
    "df_dsa_voos.describe('dep_delay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0524fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando o tipo de dado\n",
    "df_dsa_voos = df_dsa_voos.withColumn('dep_delay', df_dsa_voos.dep_delay.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85702c9-a25a-4399-a7e1-7db21939ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo \n",
    "df_dsa_voos.describe('dep_delay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7be361-e1db-4608-bcd9-743b494ea3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamento por mês e destino do voo\n",
    "by_month_dest = df_dsa_voos.groupBy('month', 'dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d5c5f-5d6f-45fd-92db-11088bea4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a média\n",
    "by_month_dest.avg('dep_delay').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fb414-406a-4c80-8a40-e7a5bd4b3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_aeroportos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090abfff-9fae-4ccd-a1a8-6e95c64d507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o título da coluna\n",
    "df_dsa_aeroportos = df_dsa_aeroportos.withColumnRenamed('faa', 'dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d6d4f-2bab-4954-9df9-0a560e3e591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_aeronaves.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825bb17-aef7-45f9-ba4b-3e87b54763e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o título da coluna\n",
    "df_dsa_aeronaves = df_dsa_aeronaves.withColumnRenamed('year', 'plane_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30bf70",
   "metadata": {},
   "source": [
    "<!-- Projeto Desenvolvido na Data Science Academy - www.datascienceacademy.com.br -->\n",
    "## Concatenando os Datasets e Preparando o Dataset Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7abeb-089b-4e03-9182-ef12361cbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_aeroportos.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655f099-2396-4563-9789-86aa86cd2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_voos.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d9d8d-76ab-4fa8-b263-c9f7a09d6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_aeronaves.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1de4e8-f708-4740-a7af-1d22e020e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena 2 datasets\n",
    "df_dsa_voos_aeroportos = df_dsa_voos.join(df_dsa_aeroportos, on='dest', how='leftouter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f66403-08f6-4edb-a473-f0684803a2bd",
   "metadata": {},
   "source": [
    "**on='dest':** Este parâmetro especifica que o join deve ser feito com base na coluna dest (destino) presente nos dois DataFrames. Neste caso, está associando os dados de voos (df_dsa_voos) com os dados dos aeroportos (df_dsa_aeroportos) com base na coluna dest, que representa o aeroporto de destino dos voos.\n",
    "\n",
    "**how='leftouter':** Especifica o tipo de join. O 'leftouter' (ou LEFT OUTER JOIN) significa que todos os registros do DataFrame à esquerda (df_dsa_voos) serão mantidos, e os registros correspondentes do DataFrame à direita (df_dsa_aeroportos) serão adicionados.\n",
    "Se não houver correspondência no DataFrame da direita (df_dsa_aeroportos), os valores das colunas do DataFrame direito serão null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edec953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_voos_aeroportos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcd763-3f75-43b0-8d1a-3d87b134512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatena 2 datasets\n",
    "df_dsa_final = df_dsa_voos_aeroportos.join(df_dsa_aeronaves, on='tailnum', how='leftouter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abdc28-d9c1-4bba-b621-8015b13c2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccabbd-cb1f-48cc-96ed-ef2d383c1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta o tipo de dado\n",
    "df_dsa_final = df_dsa_final.withColumn('month', df_dsa_final.month.cast('integer'))\n",
    "df_dsa_final = df_dsa_final.withColumn('air_time' , df_dsa_final.air_time.cast('integer'))\n",
    "df_dsa_final = df_dsa_final.withColumn('arr_delay', df_dsa_final.arr_delay.cast('integer'))\n",
    "df_dsa_final = df_dsa_final.withColumn('plane_year', df_dsa_final.plane_year.cast('integer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47744b41-5626-4596-b960-ef171ff9dccd",
   "metadata": {},
   "source": [
    "## Engenharia de Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9acf0-3a5b-454b-9a87-a9dacd3e5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.describe('month', 'air_time', 'arr_delay', 'plane_year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122e420-7d16-4099-b585-1af066c6f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma variável com a idade do avião\n",
    "df_dsa_final = df_dsa_final.withColumn('plane_age', df_dsa_final.year - df_dsa_final.plane_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b31300-dab7-4ed7-82a4-9b69001418c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.select('month', 'air_time', 'arr_delay', 'plane_age').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a95f82-0c72-4847-a27f-16dc68b00c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a variável \"is_late\" somente para os casos onde o atraso na chegada foi maior do que zero\n",
    "df_dsa_final = df_dsa_final.withColumn('is_late', df_dsa_final.arr_delay > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06093d3d-b56f-4ba1-a8f7-1d9546ca1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.select('month', 'air_time', 'arr_delay', 'plane_age', 'is_late').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8430b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variável alvo (label) será \"is_late\", ou seja, se o voo vai atrasar ou não\n",
    "# Observe que o nome da coluna precisa ser \"label\" pois isso que o Spark espera como nome da coluna alvo\n",
    "df_dsa_final = df_dsa_final.withColumn('label', df_dsa_final.is_late.cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e86e133-0c54-4993-863e-b8d4ed1ef66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.select('month', 'air_time', 'arr_delay', 'plane_age', 'is_late', 'label').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c576f",
   "metadata": {},
   "source": [
    "## Pré-Processamento com String Indexer e One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b84682-3f3a-4401-9c10-a0bfd43de80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dsa_final.select('carrier', 'dest').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd048c8-8edc-4051-ab03-2289ff9131fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os indexadores StringIndexer\n",
    "carr_indexer = StringIndexer(inputCol='carrier', outputCol='carrier_index')\n",
    "dest_indexer = StringIndexer(inputCol='dest', outputCol='dest_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os codificadores OneHotEncoder\n",
    "carr_encoder = OneHotEncoder(inputCol='carrier_index', outputCol='carr_fact')\n",
    "dest_encoder = OneHotEncoder(inputCol='dest_index', outputCol='dest_fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b7ea4-36f9-4f49-86a8-ebf4b863ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o vector assembler apenas fazendo skip para qualquer registro inválido\n",
    "# As variáveis de entrada estarão no vetor chamado features (tem que ser esse nome, o que é requerido pelo Spark)\n",
    "vec_assembler = VectorAssembler(inputCols = ['month', 'air_time', 'carr_fact', 'dest_fact', 'plane_age'],\n",
    "                                outputCol = 'features',\n",
    "                                handleInvalid = \"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e6e26-1afb-4645-9eea-ee78f4d0c208",
   "metadata": {},
   "source": [
    "- Dados de entrada --> ['month', 'air_time', 'carr_fact', 'dest_fact', 'plane_age'] como o vetor features.\n",
    "- Dados de saída --> ['is_late'] com o nome label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf8729",
   "metadata": {},
   "source": [
    "## Criando o Pipeline de Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7433fa3-d372-42bf-849d-7434621963de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o pipeline de transformação e pré-processamento\n",
    "dsa_pipe = Pipeline(stages = [dest_indexer, dest_encoder, carr_indexer, carr_encoder, vec_assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853652e4-5967-498a-bc60-27b1f2218af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina e aplica o pipeline\n",
    "piped_data = dsa_pipe.fit(df_dsa_final).transform(df_dsa_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb27b7-4c2c-406a-a20e-544138634227",
   "metadata": {},
   "outputs": [],
   "source": [
    "piped_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a828ebd-f9ba-45d4-a587-d5ee3d14c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de entrada e saída\n",
    "piped_data.select(\"features\", \"label\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4ef25-0678-4f45-9044-c11c1be7375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados em treino e teste com proporção 70/30\n",
    "dados_treino, dados_teste = piped_data.randomSplit([.7, .3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817743e8",
   "metadata": {},
   "source": [
    "## Ajustando o Número de Partições"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9446d65",
   "metadata": {},
   "source": [
    "Se as partições dos dados forem muito grandes, o Spark pode ter dificuldades para distribuí-las eficientemente. Ajustar o tamanho das partições pode ajudar no processamento. Você pode utilizar o método repartition para dividir os dados em mais ou menos partições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a955b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolha um número de partições adequado ao tamanho do seu cluster e dos seus dados\n",
    "dados_treino = dados_treino.repartition(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045901d",
   "metadata": {},
   "source": [
    "## Pipeline de Treinamento do Modelo de IA com PySpark em Ambiente Distribuído"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1404be",
   "metadata": {},
   "source": [
    "## Versão 1 do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2ee6b-854a-478e-a599-401661fd275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Inicializa o modelo RandomForest\n",
    "modelo_dsa_rf = RandomForestClassifier()\n",
    "\n",
    "# Avaliador para medir a métrica \"areaUnderROC\"\n",
    "evaluator = BinaryClassificationEvaluator(metricName = 'areaUnderROC')\n",
    "\n",
    "# Cria o grid de parâmetros\n",
    "grid = ParamGridBuilder()\n",
    "\n",
    "# Adiciona os hiperparâmetros ao grid\n",
    "grid = grid.addGrid(modelo_dsa_rf.numTrees, [10, 50, 100])\n",
    "grid = grid.addGrid(modelo_dsa_rf.maxDepth, [5, 10, 20])\n",
    "\n",
    "# Constrói o grid\n",
    "grid = grid.build()\n",
    "\n",
    "# Cria o CrossValidator\n",
    "cv = CrossValidator(estimator = modelo_dsa_rf,\n",
    "                    estimatorParamMaps = grid,\n",
    "                    evaluator = evaluator)\n",
    "\n",
    "# Treina os modelos com validação cruzada\n",
    "modelos = cv.fit(dados_treino)\n",
    "\n",
    "# Extrai o melhor modelo\n",
    "best_rf = modelos.bestModel\n",
    "\n",
    "# Usa o modelo para prever o conjunto de teste\n",
    "test_results_rf = best_rf.transform(dados_teste)\n",
    "\n",
    "# Avalia as previsões\n",
    "print(evaluator.evaluate(test_results_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a437169",
   "metadata": {},
   "source": [
    "## Versão 2 do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa39d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Incializa o modelo de Regressão Logística\n",
    "modelo_dsa_rl = LogisticRegression()\n",
    "\n",
    "# Avaliador para medir a métrica \"areaUnderROC\"\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName = 'areaUnderROC')\n",
    "\n",
    "# Cria o grid de parâmetros\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# Adiciona os hiperparâmetros ao grid\n",
    "grid = grid.addGrid(modelo_dsa_rl.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(modelo_dsa_rl.elasticNetParam, [0,1])\n",
    "\n",
    "# Constrói o grid\n",
    "grid = grid.build()\n",
    "\n",
    "# Cria o CrossValidator\n",
    "cv = tune.CrossValidator(estimator = modelo_dsa_rl,\n",
    "                         estimatorParamMaps = grid,\n",
    "                         evaluator = evaluator)\n",
    "\n",
    "# Treina os modelos com validação cruzada\n",
    "modelos = cv.fit(dados_treino)\n",
    "\n",
    "# Extrai o melhor modelo\n",
    "best_lr = modelos.bestModel\n",
    "\n",
    "# Usa o modelo para prever o conjunto de teste\n",
    "test_results_rl = best_lr.transform(dados_teste)\n",
    "\n",
    "# Avalia as previsões\n",
    "print(evaluator.evaluate(test_results_rl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a3ae1",
   "metadata": {},
   "source": [
    "## Salvando Dados e Modelo em Formato Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ea4e1-fbb2-4a12-90f3-49c95db2e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o DataFrame de treino em formato Parquet\n",
    "dados_treino.write.mode('overwrite').parquet('/opt/spark/data/dados_treino.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0474ae79-b891-4655-b5d0-f41bd434473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o DataFrame de teste em formato Parquet\n",
    "dados_teste.write.mode('overwrite').parquet('/opt/spark/data/dados_teste.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e0ae4-913d-4b9a-9937-c7adc91c34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o melhor modelo no disco\n",
    "best_lr.write().overwrite().save('/opt/spark/data/dsa_melhor_modelo_lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abac73-d57f-462d-8a7b-84a7715b194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se os dados foram salvos no HDFS\n",
    "!hdfs dfs -ls /opt/spark/data/ | awk '{print $1, $2, $3, $4, $8}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacde2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6f357",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
